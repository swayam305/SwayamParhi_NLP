{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 6277,
          "databundleVersionId": 323734,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import losses, evaluation\n",
        "import zipfile\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from datasets import Dataset\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, losses\n",
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "from sentence_transformers.similarity_functions import SimilarityFunction\n",
        "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
        "from sentence_transformers.training_args import SentenceTransformerTrainingArguments"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T14:36:20.996904Z",
          "iopub.execute_input": "2025-09-07T14:36:20.997161Z",
          "iopub.status.idle": "2025-09-07T14:36:59.271945Z",
          "shell.execute_reply.started": "2025-09-07T14:36:20.997135Z",
          "shell.execute_reply": "2025-09-07T14:36:59.271137Z"
        },
        "id": "4N-amCuGgm7I",
        "outputId": "cfd1409c-9748-415a-f405-5697ce4ddb23"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-09-07 14:36:40.802963: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757255801.135513      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757255801.228029      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "\n",
        "with zipfile.ZipFile(\"/kaggle/input/quora-question-pairs/train.csv.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./train/\")\n",
        "\n",
        "# Load and clean data\n",
        "df = pd.read_csv(\"/kaggle/working/train/train.csv\").dropna()\n",
        "df = df.rename(columns={'is_duplicate': 'label'})[['question1', 'question2', 'label']]\n",
        "\n",
        "# Split into train+val and test (80%/20%)\n",
        "train_val, test = model_selection.train_test_split(\n",
        "    df, test_size=0.2, random_state=42, stratify=df['label']\n",
        ")\n",
        "\n",
        "# Split train+val into train and val (75%/25% of train_val)\n",
        "train, val = model_selection.train_test_split(\n",
        "    train_val, test_size=0.25, random_state=42, stratify=train_val['label']\n",
        ")\n",
        "\n",
        "# Convert to Dataset objects\n",
        "from datasets import Dataset\n",
        "train_ds = Dataset.from_pandas(train.reset_index(drop=True))\n",
        "val_ds = Dataset.from_pandas(val.reset_index(drop=True))\n",
        "test_ds = Dataset.from_pandas(test.reset_index(drop=True))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T14:37:05.182766Z",
          "iopub.execute_input": "2025-09-07T14:37:05.183046Z",
          "iopub.status.idle": "2025-09-07T14:37:07.802602Z",
          "shell.execute_reply.started": "2025-09-07T14:37:05.183024Z",
          "shell.execute_reply": "2025-09-07T14:37:07.802021Z"
        },
        "id": "0bUXVsoEgm7N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_f1(model, dataset, threshold=0.5, is_cross_encoder=False, batch_size=128):\n",
        "    q1, q2, labels = dataset['question1'], dataset['question2'], dataset['label']\n",
        "    n_samples = len(labels)\n",
        "    predictions = []\n",
        "\n",
        "    if is_cross_encoder:\n",
        "        from sentence_transformers import CrossEncoder\n",
        "        if not isinstance(model, CrossEncoder):\n",
        "            model = CrossEncoder(model)\n",
        "\n",
        "        # Process in batches\n",
        "        for i in tqdm(range(0, n_samples, batch_size), desc=\"Evaluating Cross-Encoder\"):\n",
        "            batch_q1 = q1[i:i+batch_size]\n",
        "            batch_q2 = q2[i:i+batch_size]\n",
        "            batch_scores = model.predict(list(zip(batch_q1, batch_q2)))\n",
        "            batch_preds = (batch_scores >= threshold).astype(int)\n",
        "            predictions.extend(batch_preds)\n",
        "\n",
        "    else:\n",
        "        # Process question1 and question2 separately in batches\n",
        "        emb1_list, emb2_list = [], []\n",
        "\n",
        "        # Encode question1 in batches\n",
        "        for i in tqdm(range(0, n_samples, batch_size), desc=\"Encoding question1\"):\n",
        "            batch_q1 = q1[i:i+batch_size]\n",
        "            emb1_batch = model.encode(batch_q1, convert_to_tensor=False, show_progress_bar=False)\n",
        "            emb1_list.append(emb1_batch)\n",
        "\n",
        "        # Encode question2 in batches\n",
        "        for i in tqdm(range(0, n_samples, batch_size), desc=\"Encoding question2\"):\n",
        "            batch_q2 = q2[i:i+batch_size]\n",
        "            emb2_batch = model.encode(batch_q2, convert_to_tensor=False, show_progress_bar=False)\n",
        "            emb2_list.append(emb2_batch)\n",
        "\n",
        "        # Concatenate all batches\n",
        "        emb1 = np.concatenate(emb1_list, axis=0)\n",
        "        emb2 = np.concatenate(emb2_list, axis=0)\n",
        "\n",
        "        # Normalize embeddings for cosine similarity\n",
        "        emb1_norm = emb1 / np.linalg.norm(emb1, axis=1, keepdims=True)\n",
        "        emb2_norm = emb2 / np.linalg.norm(emb2, axis=1, keepdims=True)\n",
        "\n",
        "        # Compute cosine similarity element-wise (much more memory efficient)\n",
        "        cos_scores = np.sum(emb1_norm * emb2_norm, axis=1)\n",
        "        scores = (cos_scores + 1) / 2  # Convert from [-1,1] to [0,1]\n",
        "        predictions = (scores >= threshold).astype(int)\n",
        "\n",
        "    return f1_score(labels, predictions)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T14:37:11.652584Z",
          "iopub.execute_input": "2025-09-07T14:37:11.652872Z",
          "iopub.status.idle": "2025-09-07T14:37:11.661858Z",
          "shell.execute_reply.started": "2025-09-07T14:37:11.652851Z",
          "shell.execute_reply": "2025-09-07T14:37:11.661147Z"
        },
        "id": "nWOybXdxgm7N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"model_path\": \"microsoft/xtremedistil-l6-h256-uncased\",\n",
        "\n",
        "    \"learning_rate\": 5e-4,\n",
        "    \"train_batch_size\": 256,\n",
        "    \"eval_batch_size\": 256,\n",
        "    \"epochs\": 5,\n",
        "    \"warmup_ratio\": 0.1,\n",
        "\n",
        "    \"output_dir\": \".\"\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T14:37:15.654470Z",
          "iopub.execute_input": "2025-09-07T14:37:15.654722Z",
          "iopub.status.idle": "2025-09-07T14:37:15.658485Z",
          "shell.execute_reply.started": "2025-09-07T14:37:15.654703Z",
          "shell.execute_reply": "2025-09-07T14:37:15.657949Z"
        },
        "id": "3O2hlwcBgm7O"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer(config[\"model_path\"])\n",
        "val_f1 = evaluate_f1(model, val_ds)\n",
        "print(f\"Benchmark F1-Score: {val_f1:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T14:37:17.926741Z",
          "iopub.execute_input": "2025-09-07T14:37:17.927254Z",
          "iopub.status.idle": "2025-09-07T14:38:09.343875Z",
          "shell.execute_reply.started": "2025-09-07T14:37:17.927229Z",
          "shell.execute_reply": "2025-09-07T14:38:09.343125Z"
        },
        "colab": {
          "referenced_widgets": [
            "825a6463a01445069bf744f2e03aed5e",
            "10395bfe26154150912a9956cd19d7c5",
            "16ee8213818342e8a258840637f4196a",
            "27fb7d9932cc45b5bd2b3561cd49b191"
          ]
        },
        "id": "OYI19ldUgm7P",
        "outputId": "b91f2cc1-e2f1-44d8-891f-6677f67233ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/525 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "825a6463a01445069bf744f2e03aed5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/51.0M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10395bfe26154150912a9956cd19d7c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/51.0M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16ee8213818342e8a258840637f4196a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27fb7d9932cc45b5bd2b3561cd49b191"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Encoding question1: 100%|██████████| 632/632 [00:19<00:00, 31.82it/s]\nEncoding question2: 100%|██████████| 632/632 [00:19<00:00, 32.22it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Benchmark F1-Score: 0.5393\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a more memory-efficient evaluator\n",
        "class F1Evaluator:\n",
        "    def __init__(self, dataloader, threshold=0.5):\n",
        "        self.dataloader = dataloader\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def __call__(self, model, output_path=None, epoch=-1, steps=-1):\n",
        "        all_labels = []\n",
        "        all_predictions = []\n",
        "\n",
        "        for batch in tqdm(self.dataloader, desc=\"Evaluating\"):\n",
        "            features, labels = batch\n",
        "            emb1 = model.encode(features['question1'], convert_to_tensor=False)\n",
        "            emb2 = model.encode(features['question2'], convert_to_tensor=False)\n",
        "\n",
        "            # Compute cosine similarity\n",
        "            emb1_norm = emb1 / np.linalg.norm(emb1, axis=1, keepdims=True)\n",
        "            emb2_norm = emb2 / np.linalg.norm(emb2, axis=1, keepdims=True)\n",
        "            cos_scores = np.sum(emb1_norm * emb2_norm, axis=1)\n",
        "            scores = (cos_scores + 1) / 2\n",
        "\n",
        "            predictions = (scores >= self.threshold).astype(int)\n",
        "            all_labels.extend(labels.numpy())\n",
        "            all_predictions.extend(predictions)\n",
        "\n",
        "        f1 = f1_score(all_labels, all_predictions)\n",
        "        return f1"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T14:38:13.213879Z",
          "iopub.execute_input": "2025-09-07T14:38:13.214234Z",
          "iopub.status.idle": "2025-09-07T14:38:13.220723Z",
          "shell.execute_reply.started": "2025-09-07T14:38:13.214208Z",
          "shell.execute_reply": "2025-09-07T14:38:13.220012Z"
        },
        "id": "RfXzxIyEgm7P"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Train with cosine similarity loss\n",
        "train_loss = losses.CosineSimilarityLoss(model=model)\n",
        "\n",
        "args = SentenceTransformerTrainingArguments(\n",
        "    output_dir=config[\"output_dir\"],\n",
        "\n",
        "    num_train_epochs=config[\"epochs\"],\n",
        "    learning_rate=config[\"learning_rate\"],\n",
        "    per_device_train_batch_size=config[\"train_batch_size\"],\n",
        "    per_device_eval_batch_size=config[\"eval_batch_size\"],\n",
        "\n",
        "    warmup_ratio=config[\"warmup_ratio\"],\n",
        "\n",
        "    fp16=True,\n",
        "\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    loss=train_loss,\n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate on test set\n",
        "test_f1 = evaluate_f1(model, test_ds, batch_size=256)\n",
        "print(f\"CosineSimilarityLoss F1: {test_f1:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T14:38:41.062193Z",
          "iopub.execute_input": "2025-09-07T14:38:41.062666Z",
          "iopub.status.idle": "2025-09-07T15:03:55.573005Z",
          "shell.execute_reply.started": "2025-09-07T14:38:41.062639Z",
          "shell.execute_reply": "2025-09-07T15:03:55.571924Z"
        },
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "d1-qjiGLgm7Q",
        "outputId": "27dd9efb-308b-4304-b1f6-1d879e689014"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='2370' max='2370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2370/2370 24:33, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.163787</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.183700</td>\n      <td>0.136259</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.136800</td>\n      <td>0.126353</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.116500</td>\n      <td>0.117705</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.101700</td>\n      <td>0.115979</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Encoding question1: 100%|██████████| 316/316 [00:18<00:00, 16.69it/s]\nEncoding question2: 100%|██████████| 316/316 [00:19<00:00, 16.49it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "CosineSimilarityLoss F1: 0.5991\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "contrastive_loss = losses.ContrastiveLoss(model=model)\n",
        "\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    loss=contrastive_loss,\n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "test_f1 = evaluate_f1(model, test_ds, batch_size=256)\n",
        "print(f\"ContrastiveLoss F1: {test_f1:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T15:03:59.816233Z",
          "iopub.execute_input": "2025-09-07T15:03:59.816824Z",
          "iopub.status.idle": "2025-09-07T15:29:07.993903Z",
          "shell.execute_reply.started": "2025-09-07T15:03:59.816799Z",
          "shell.execute_reply": "2025-09-07T15:29:07.993031Z"
        },
        "id": "z30woKQXgm7R",
        "outputId": "782469f7-6f81-47ac-be12-9e9d9466e49e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='2370' max='2370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2370/2370 24:28, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.014748</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.012500</td>\n      <td>0.014018</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.010700</td>\n      <td>0.013862</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.008900</td>\n      <td>0.013769</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.007600</td>\n      <td>0.013544</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Encoding question1: 100%|██████████| 316/316 [00:18<00:00, 17.00it/s]\nEncoding question2: 100%|██████████| 316/316 [00:19<00:00, 16.57it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "ContrastiveLoss F1: 0.5451\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter only positive pairs for MNRL\n",
        "pos_indices = [i for i, label in enumerate(train_ds['label']) if label == 1]\n",
        "pos_train_ds = train_ds.select(pos_indices)\n",
        "\n",
        "mnrl_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
        "\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=pos_train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    loss=mnrl_loss,\n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "test_f1 = evaluate_f1(model, test_ds, batch_size=256)\n",
        "print(f\"MNRL F1: {test_f1:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T15:29:42.321252Z",
          "iopub.execute_input": "2025-09-07T15:29:42.321975Z",
          "iopub.status.idle": "2025-09-07T15:38:46.384957Z",
          "shell.execute_reply.started": "2025-09-07T15:29:42.321951Z",
          "shell.execute_reply": "2025-09-07T15:38:46.384350Z"
        },
        "id": "j7WH0Qrqgm7R",
        "outputId": "340a0348-9a96-4564-bfdd-5edf040a9e8e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='875' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [875/875 08:23, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>2.068440</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.914759</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.349400</td>\n      <td>1.854747</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.349400</td>\n      <td>1.829723</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.349400</td>\n      <td>1.832685</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Encoding question1: 100%|██████████| 316/316 [00:18<00:00, 17.11it/s]\nEncoding question2: 100%|██████████| 316/316 [00:18<00:00, 16.71it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "MNRL F1: 0.5534\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "\n",
        "# Load tokenizer and model for sequence classification\n",
        "tokenizer = AutoTokenizer.from_pretrained(config[\"model_path\"])\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    config[\"model_path\"], num_labels=2\n",
        ")\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    texts = [(q1, q2) for q1, q2 in zip(examples[\"question1\"], examples[\"question2\"])]\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "# Tokenize datasets\n",
        "tokenized_train = train_ds.map(tokenize_function, batched=True)\n",
        "tokenized_val = val_ds.map(tokenize_function, batched=True)\n",
        "tokenized_test = test_ds.map(tokenize_function, batched=True)\n",
        "\n",
        "# Format datasets for PyTorch\n",
        "tokenized_train = tokenized_train.rename_column(\"label\", \"labels\")\n",
        "tokenized_val = tokenized_val.rename_column(\"label\", \"labels\")\n",
        "tokenized_test = tokenized_test.rename_column(\"label\", \"labels\")\n",
        "\n",
        "tokenized_train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "tokenized_val.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "tokenized_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Metrics function for evaluation\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    f1 = f1_score(labels, predictions, average='weighted')\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision = precision_score(labels, predictions, average='weighted')\n",
        "    recall = recall_score(labels, predictions, average='weighted')\n",
        "\n",
        "    return {\n",
        "        'f1': f1,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=config[\"output_dir\"],\n",
        "    learning_rate=config[\"learning_rate\"],\n",
        "    per_device_train_batch_size=config[\"train_batch_size\"],\n",
        "    per_device_eval_batch_size=config[\"eval_batch_size\"],\n",
        "    num_train_epochs=config[\"epochs\"],\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    warmup_ratio=config[\"warmup_ratio\"],\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=500,\n",
        "    save_total_limit=2,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"Training cross-encoder model...\")\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "trainer.save_model()\n",
        "tokenizer.save_pretrained(config[\"output_dir\"])\n",
        "# Evaluate on test set\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "test_results = trainer.evaluate(tokenized_test)\n",
        "print(f\"Test Results:\")\n",
        "print(f\"F1-Score: {test_results['eval_f1']:.4f}\")\n",
        "print(f\"Accuracy: {test_results['eval_accuracy']:.4f}\")\n",
        "print(f\"Precision: {test_results['eval_precision']:.4f}\")\n",
        "print(f\"Recall: {test_results['eval_recall']:.4f}\")\n",
        "\n",
        "# Get detailed predictions on test set\n",
        "test_predictions = trainer.predict(tokenized_test)\n",
        "predicted_labels = np.argmax(test_predictions.predictions, axis=1)\n",
        "true_labels = test_predictions.label_ids\n",
        "\n",
        "# Detailed classification report\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(true_labels, predicted_labels, target_names=['Not Duplicate', 'Duplicate']))\n",
        "\n",
        "# Calculate and display F1-score\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "print(f\"Final F1-Score on test set: {f1:.4f}\")\n",
        "\n",
        "# Example predictions\n",
        "print(\"\\nSample predictions from test set:\")\n",
        "sample_indices = np.random.choice(len(test), 5, replace=False)\n",
        "for i in sample_indices:\n",
        "    q1 = test.iloc[i][\"question1\"]\n",
        "    q2 = test.iloc[i][\"question2\"]\n",
        "    true_label = test.iloc[i][\"label\"]\n",
        "    pred_label = predicted_labels[i]\n",
        "\n",
        "    print(f\"Q1: {q1}\")\n",
        "    print(f\"Q2: {q2}\")\n",
        "    print(f\"True: {'Duplicate' if true_label == 1 else 'Not Duplicate'}\")\n",
        "    print(f\"Pred: {'Duplicate' if pred_label == 1 else 'Not Duplicate'}\")\n",
        "    print(f\"Correct: {true_label == pred_label}\")\n",
        "    print(\"-\" * 80)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T15:40:48.733206Z",
          "iopub.execute_input": "2025-09-07T15:40:48.733755Z",
          "iopub.status.idle": "2025-09-07T16:04:53.475628Z",
          "shell.execute_reply.started": "2025-09-07T15:40:48.733732Z",
          "shell.execute_reply": "2025-09-07T16:04:53.474987Z"
        },
        "colab": {
          "referenced_widgets": [
            "8d2e73adff50473d95c5e4aafb87bfac",
            "e2c588ae36b5499793bc2f342b141494",
            "5b16c3e73d894afbb7608e4b6594e133"
          ]
        },
        "id": "aEo7sEDzgm7S",
        "outputId": "b62d7015-f624-41f8-f26e-e80a4694de95"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/xtremedistil-l6-h256-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/242571 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d2e73adff50473d95c5e4aafb87bfac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/80858 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2c588ae36b5499793bc2f342b141494"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/80858 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b16c3e73d894afbb7608e4b6594e133"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_36/2506271868.py:83: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Training cross-encoder model...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='2370' max='2370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2370/2370 22:11, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.308227</td>\n      <td>0.861322</td>\n      <td>0.862017</td>\n      <td>0.861139</td>\n      <td>0.862017</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.391000</td>\n      <td>0.287632</td>\n      <td>0.876773</td>\n      <td>0.875436</td>\n      <td>0.882196</td>\n      <td>0.875436</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.277700</td>\n      <td>0.310986</td>\n      <td>0.888358</td>\n      <td>0.887618</td>\n      <td>0.890378</td>\n      <td>0.887618</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.219600</td>\n      <td>0.284841</td>\n      <td>0.892064</td>\n      <td>0.891835</td>\n      <td>0.892408</td>\n      <td>0.891835</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.174900</td>\n      <td>0.304377</td>\n      <td>0.893085</td>\n      <td>0.892552</td>\n      <td>0.894306</td>\n      <td>0.892552</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEvaluating on test set...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Test Results:\nF1-Score: 0.8939\nAccuracy: 0.8933\nPrecision: 0.8950\nRecall: 0.8933\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nDetailed Classification Report:\n               precision    recall  f1-score   support\n\nNot Duplicate       0.93      0.90      0.91     51005\n    Duplicate       0.84      0.88      0.86     29853\n\n     accuracy                           0.89     80858\n    macro avg       0.88      0.89      0.89     80858\n weighted avg       0.90      0.89      0.89     80858\n\nFinal F1-Score on test set: 0.8592\n\nSample predictions from test set:\nQ1: Is the new TV show “Westworld” worth watching?\nQ2: Is westworld worth watching?\nTrue: Duplicate\nPred: Duplicate\nCorrect: True\n--------------------------------------------------------------------------------\nQ1: Is daily masturbation causes any hair fall?\nQ2: Does excessive masturbation lead to hair loss?\nTrue: Duplicate\nPred: Duplicate\nCorrect: True\n--------------------------------------------------------------------------------\nQ1: How do I study 7th grade?\nQ2: I am in college studying the foundation of science. I really want to keep up my good grade. How do I do a study schedule?\nTrue: Not Duplicate\nPred: Not Duplicate\nCorrect: True\n--------------------------------------------------------------------------------\nQ1: I am a mechanical engineer with no knowledge of programming. What is the best way to learn Python?\nQ2: What is the best source to learn Python?\nTrue: Duplicate\nPred: Duplicate\nCorrect: True\n--------------------------------------------------------------------------------\nQ1: Why was Jaqen H'ghar captured in the first place with the other two prisoners if he has such skills?\nQ2: Why was Jaqen H'ghar being sent to Castle Black?\nTrue: Not Duplicate\nPred: Not Duplicate\nCorrect: True\n--------------------------------------------------------------------------------\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "rAZJ7TEigm7U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "gel7tAlwgm7U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "dPnnB1jPgm7V"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}